
= * 80
 ğŸ”¥ğŸ”¥ğŸ”¥ PSYCHO MODE LLM API TESTING SUITE ğŸ”¥ğŸ”¥ğŸ”¥
= * 80
âš ï¸  PSYCHO MODE ENABLED - SHOWING EVERY REQUEST AND RESPONSE!
â„¹ï¸  Base URL: http://localhost:4000

= * 80
 ğŸ“‹ TESTING MODELS LIST ENDPOINT
= * 80

- * 60
 List Available Models
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/models
ğŸ“¤ REQUEST: METHOD: GET
ğŸ“¤ REQUEST: BODY: (empty)

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=648
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "models": [
      {
        "model": "gpt-4.1",
        "display_name": "OpenAI - GPT-4.1",
        "house": "OpenAI",
        "model_type": "text_gen"
      },
      {
        "model": "claude-sonnet-4-20250514",
        "display_name": "Anthropic - Claude Sonnet 4",
        "house": "Anthropic",
        "model_type": "text_gen"
      },
      {
        "model": "gemini-2.5-pro",
        "display_name": "Google - Gemini 2.5 Flash",
        "house": "Google",
        "model_type": "text_gen"
      },
      {
        "model": "gemini-2.5",
        "display_name": "Google - Gemini 2.5",
        "house": "Google",
        "model_type": "text_gen"
      },
      {
        "model": "gemini-2.5-pro",
        "display_name": "Google - Gemini 2.5 Pro",
        "house": "Google",
        "model_type": "text_gen"
      }
    ]
  },
  "metadata": {
    "timestamp": "2025-07-23T04:33:44.102Z",
    "totalCount": 5
  },
  "success": true
}

âœ… âœ¨ List Available Models - PASSED âœ¨
âœ… Found 5 available models:
  ğŸ¤– gpt-4.1 (OpenAI) - OpenAI - GPT-4.1
  ğŸ¤– claude-sonnet-4-20250514 (Anthropic) - Anthropic - Claude Sonnet 4
  ğŸ¤– gemini-2.5-pro (Google) - Google - Gemini 2.5 Flash
  ğŸ¤– gemini-2.5 (Google) - Google - Gemini 2.5
  ğŸ¤– gemini-2.5-pro (Google) - Google - Gemini 2.5 Pro

= * 80
 ğŸ¤– TESTING OPENAI PROVIDER
= * 80

- * 60
 OpenAI - Basic Generation
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gpt-4.1",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.7,
    "max_tokens": 50
  }
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=392
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "Medieval monk, Europe, 12th century",
    "generationId": "req_b8176684b411c269"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:33:47.269Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.7,
      "finishReason": "stop"
    },
    "tokens": {
      "input": 34,
      "output": 10,
      "total": 44,
      "maxRequested": 50
    },
    "provider": "openai",
    "model": "gpt-4.1",
    "timing": {
      "responseMs": 1064
    }
  },
  "success": true
}

âœ… âœ¨ OpenAI - Basic Generation - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'Medieval monk, Europe, 12th century'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 35 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=34, Output=10, Total=44, MaxRequested=50
â„¹ï¸  â±ï¸  TIMING: 1064ms
â„¹ï¸  ğŸ¤– PROVIDER: openai / MODEL: gpt-4.1
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.7, FinishReason=stop

Name                           Value
----                           -----
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

- * 60
 OpenAI - Prompt Polishing (YOUR USE CASE)
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gpt-4.1",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.7,
    "max_tokens": 50
  }
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=391
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "Medieval European monk, 12th century",
    "generationId": "req_b9513f89b75aab48"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:33:49.813Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.7,
      "finishReason": "stop"
    },
    "tokens": {
      "input": 34,
      "output": 9,
      "total": 43,
      "maxRequested": 50
    },
    "provider": "openai",
    "model": "gpt-4.1",
    "timing": {
      "responseMs": 455
    }
  },
  "success": true
}

âœ… âœ¨ OpenAI - Prompt Polishing (YOUR USE CASE) - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'Medieval European monk, 12th century'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 36 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=34, Output=9, Total=43, MaxRequested=50
â„¹ï¸  â±ï¸  TIMING: 455ms
â„¹ï¸  ğŸ¤– PROVIDER: openai / MODEL: gpt-4.1
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.7, FinishReason=stop
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

- * 60
 OpenAI - Low Token Limit Stress Test
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gpt-4.1",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.5,
    "max_tokens": 20
  }
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=510
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "Medieval monk in 12th-century Western Europe",
    "generationId": "req_2eb0a66eff77c42a"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:33:52.51Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.5,
      "finishReason": "stop",
      "userRequested": 20,
      "providerAdjusted": 50,
      "adjustmentReason": "Provider minimum tokens for reliable generation"
    },
    "tokens": {
      "input": 34,
      "output": 10,
      "total": 44,
      "maxRequested": 50
    },
    "provider": "openai",
    "model": "gpt-4.1",
    "timing": {
      "responseMs": 626
    }
  },
  "success": true
}

âœ… âœ¨ OpenAI - Low Token Limit Stress Test - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'Medieval monk in 12th-century Western Europe'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 44 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=34, Output=10, Total=44, MaxRequested=50
â„¹ï¸  â±ï¸  TIMING: 626ms
â„¹ï¸  ğŸ¤– PROVIDER: openai / MODEL: gpt-4.1
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.5, FinishReason=stop
âš ï¸  âš™ï¸  TOKEN ADJUSTMENT: 20 â†’ 50 (Provider minimum tokens for reliable generation)
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

- * 60
 OpenAI - No Options (Default Behavior)
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gpt-4.1",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {}
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=493
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "Medieval monk in 13th-century Western Europe",
    "generationId": "req_a41dbd45ba224cf9"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:33:55.308Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.7,
      "finishReason": "stop",
      "providerAdjusted": 100,
      "adjustmentReason": "Provider minimum tokens for reliable generation"
    },
    "tokens": {
      "input": 34,
      "output": 10,
      "total": 44,
      "maxRequested": 100
    },
    "provider": "openai",
    "model": "gpt-4.1",
    "timing": {
      "responseMs": 687
    }
  },
  "success": true
}

âœ… âœ¨ OpenAI - No Options (Default Behavior) - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'Medieval monk in 13th-century Western Europe'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 44 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=34, Output=10, Total=44, MaxRequested=100
â„¹ï¸  â±ï¸  TIMING: 687ms
â„¹ï¸  ğŸ¤– PROVIDER: openai / MODEL: gpt-4.1
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.7, FinishReason=stop
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

= * 80
 ğŸ§  TESTING ANTHROPIC PROVIDER
= * 80

- * 60
 Anthropic - Basic Generation
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "claude-sonnet-4-20250514",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.7,
    "max_tokens": 50
  }
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=539
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "Medieval European monastery scribe, 12th century",
    "generationId": "req_9ec2eba4a4c8b1d8"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:33:59.47Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.7,
      "finishReason": "end_turn",
      "userRequested": 50,
      "providerAdjusted": 75,
      "adjustmentReason": "Provider minimum tokens for reliable generation"
    },
    "tokens": {
      "input": 38,
      "output": 13,
      "total": 51,
      "maxRequested": 75
    },
    "provider": "anthropic",
    "model": "claude-sonnet-4-20250514",
    "timing": {
      "responseMs": 2068
    }
  },
  "success": true
}

âœ… âœ¨ Anthropic - Basic Generation - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'Medieval European monastery scribe, 12th century'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 48 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=38, Output=13, Total=51, MaxRequested=75
â„¹ï¸  â±ï¸  TIMING: 2068ms
â„¹ï¸  ğŸ¤– PROVIDER: anthropic / MODEL: claude-sonnet-4-20250514
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.7, FinishReason=end_turn
âš ï¸  âš™ï¸  TOKEN ADJUSTMENT: 50 â†’ 75 (Provider minimum tokens for reliable generation)
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

- * 60
 Anthropic - Prompt Polishing
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "claude-sonnet-4-20250514",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.6,
    "max_tokens": 75
  }
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=429
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "Medieval European monastery scribe, 12th century",
    "generationId": "req_9be3a77650552def"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:34:03.167Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.6,
      "finishReason": "end_turn"
    },
    "tokens": {
      "input": 38,
      "output": 13,
      "total": 51,
      "maxRequested": 75
    },
    "provider": "anthropic",
    "model": "claude-sonnet-4-20250514",
    "timing": {
      "responseMs": 1615
    }
  },
  "success": true
}

âœ… âœ¨ Anthropic - Prompt Polishing - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'Medieval European monastery scribe, 12th century'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 48 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=38, Output=13, Total=51, MaxRequested=75
â„¹ï¸  â±ï¸  TIMING: 1615ms
â„¹ï¸  ğŸ¤– PROVIDER: anthropic / MODEL: claude-sonnet-4-20250514
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.6, FinishReason=end_turn
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

= * 80
 ğŸ’ TESTING GEMINI PROVIDER
= * 80

- * 60
 Gemini - Basic Generation
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gemini-2.5-pro",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.7,
    "max_tokens": 8192
  }
}

â„¹ï¸  ğŸš€ Sending request...
âŒ ğŸ’¥ Gemini - Basic Generation - EXCEPTION: Response status code does not indicate success: 500 (Internal Server Error).
Error                          Response status code does not indicate success: 500 (Internal Server Error).
Success                        False

- * 60
 Gemini - Prompt Polishing
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gemini-2.5-pro",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.7,
    "max_tokens": 8192
  }
}

â„¹ï¸  ğŸš€ Sending request...
ğŸ“¥ RESPONSE: STATUS: 200
ğŸ“¥ RESPONSE: HEADERS: Content-Type=application/json; charset=utf-8, Length=419
ğŸ“¥ RESPONSE: BODY:
{
  "data": {
    "content": "An English monk illuminates a manuscript, c. 1300.",
    "generationId": "req_504a65272651c247"
  },
  "metadata": {
    "request": {
      "timestamp": "2025-07-23T04:36:01.431Z",
      "attemptNumber": 1,
      "retryCount": 0
    },
    "config": {
      "temperature": 0.7,
      "finishReason": "STOP"
    },
    "tokens": {
      "input": 28,
      "output": 15,
      "total": 1758,
      "maxRequested": 8192
    },
    "provider": "gemini",
    "model": "gemini-2.5-pro",
    "timing": {
      "responseMs": 20507
    }
  },
  "success": true
}

âœ… âœ¨ Gemini - Prompt Polishing - PASSED âœ¨
â„¹ï¸  ğŸ“ CONTENT: 'An English monk illuminates a manuscript, c. 1300.'
â„¹ï¸  ğŸ“ CONTENT LENGTH: 50 characters
â„¹ï¸  ğŸ¯ TOKENS: Input=28, Output=15, Total=1758, MaxRequested=8192
â„¹ï¸  â±ï¸  TIMING: 20507ms
â„¹ï¸  ğŸ¤– PROVIDER: gemini / MODEL: gemini-2.5-pro
â„¹ï¸  ğŸ”§ CONFIG: Temperature=0.7, FinishReason=STOP
StatusCode                     200
Success                        True
Response                       @{data=; metadata=; success=True}

- * 60
 Gemini - Very Low Tokens (Edge Case)
- * 60
ğŸ“¤ REQUEST: URL: http://localhost:4000/api/llm/generate
ğŸ“¤ REQUEST: METHOD: POST
ğŸ“¤ REQUEST: BODY:
{
  "model": "gemini-2.5-pro",
  "prompt": "Please polish this prompt. Make it nicer. Mention time & geography in history. Reply ONLY response. MAX 50 characters: Medieval monk",
  "options": {
    "temperature": 0.7,
    "max_tokens": 20
  }
}

â„¹ï¸  ğŸš€ Sending request...
